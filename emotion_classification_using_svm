# -*- coding: utf-8 -*-
"""Emotion Classification from Tweets using SVM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KUVc1ze22e8RuDrDu6Vygz98dfDw2IUo
"""

import pandas as pd
import numpy as np
import re
import string
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import KMeans
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import nltk
import os

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Load dataset
data = pd.read_csv('/content/emotions.csv')

# Handle missing values and duplicates
data.dropna(inplace=True)
data.drop_duplicates(subset='text', inplace=True)

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    text = re.sub(r'\@\w+|\#', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    text = text.strip()
    tokens = text.split()
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    stemmer = PorterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]
    return ' '.join(tokens)

# Apply preprocessing
data['cleaned_text'] = data['text'].apply(preprocess_text)

# Encode labels
label_encoder = LabelEncoder()
data['encoded_label'] = label_encoder.fit_transform(data['label'])

# Train-test split
X = data['cleaned_text']
y = data['encoded_label']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=20000)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Optional: use only a subset of training data for speed
X_train_tfidf = X_train_tfidf[:20000]
y_train = y_train[:20000]

# Function to evaluate SVM with different kernels
def evaluate_svm(kernel_type):
    print(f"\nEvaluating SVM with {kernel_type} kernel")
    model = SVC(kernel=kernel_type, random_state=42)
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)

    acc = accuracy_score(y_test, y_pred)
    report_dict = classification_report(
        y_test, y_pred, target_names=label_encoder.classes_.astype(str), output_dict=True)

    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_.astype(str)))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title(f'Confusion Matrix - {kernel_type} kernel')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.show()

    return acc, report_dict

# Evaluate all kernels
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
results = {}

for kernel in kernels:
    accuracy, report = evaluate_svm(kernel)
    results[kernel] = {
        'accuracy': accuracy,
        'precision': report['weighted avg']['precision'],
        'recall': report['weighted avg']['recall'],
        'f1-score': report['weighted avg']['f1-score']
    }

# Summarize performance
results_df = pd.DataFrame(results).T
print("\nPerformance summary:")
print(results_df)

# Plot performance
plt.figure(figsize=(10, 6))
results_df.plot(kind='bar', y=['accuracy', 'precision', 'recall', 'f1-score'],
                title='SVM Kernel Performance Comparison')
plt.xticks(rotation=0)
plt.ylabel('Score')
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

# Save best model
best_kernel = results_df['accuracy'].idxmax()
print(f"\nBest performing kernel: {best_kernel}")
best_model = SVC(kernel=best_kernel, random_state=42)
best_model.fit(X_train_tfidf, y_train)

joblib.dump(best_model, 'best_svm_model.pkl')
joblib.dump(tfidf, 'tfidf_vectorizer.pkl')
joblib.dump(label_encoder, 'label_encoder.pkl')
print("\nâœ… Model and components saved")

# Alert system
def alert_emotion(text):
    cleaned = preprocess_text(text)
    vec = tfidf.transform([cleaned])
    pred = best_model.predict(vec)[0]
    emotion = str(label_encoder.inverse_transform([pred])[0])  # Ensure it's a string
    print(f"Predicted Emotion: {emotion.upper()}")
    if emotion in ['sadness', 'anger', 'fear']:
        print("ðŸš¨ ALERT: Negative emotion detected!")

# Example
alert_emotion("I feel really down and anxious today.")

# Clustering with KMeans
kmeans = KMeans(n_clusters=6, random_state=42)
kmeans_labels = kmeans.fit_predict(X_train_tfidf)

plt.figure(figsize=(6, 4))
sns.countplot(x=kmeans_labels)
plt.title("KMeans Clustering Distribution")
plt.xlabel("Cluster")
plt.ylabel("Count")
plt.tight_layout()
plt.show()
